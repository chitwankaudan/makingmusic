{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Generation using an LSTM\n",
    "\n",
    "#### Final Project for Deep Learning (CS 7643)\n",
    "\n",
    "By Daeil Cha, Daniel Dias, Chitwan Kaudan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"../../lmd_matched\"\n",
    "data_path = \"../clean-data\"\n",
    "saved_models_path = \"../saved-models\"\n",
    "\n",
    "num_epochs = 10 # 1000\n",
    "batch_size = 10\n",
    "num_time_steps = 256\n",
    "num_total_songs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "from getdata import getBatch\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pytorch GPU/CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.FloatTensor\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# dtype = torch.cuda.DoubleTensor\n",
    "# device = torch.device(\"cuda:0\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "all_data = []\n",
    "\n",
    "while start < num_total_songs:\n",
    "    batch = np.array(getBatch(start, batch_size, num_time_steps, data_path), dtype='double')\n",
    "    all_data.append(batch)\n",
    "    # Shape should be (batch_size x num_time_steps x note_range x pitch/articulation)\n",
    "    start += batch_size\n",
    "\n",
    "all_data = np.concatenate(all_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 256, 78, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Input Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 78, 256, 80])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.input_function import InputKernel\n",
    "inputkernel = InputKernel.apply\n",
    "\n",
    "note_state_batch = torch.from_numpy(np.swapaxes(all_data,1,2)).float() \n",
    "#input kernel expects input shape = batch_size x num_notes x num_timesteps x 2\n",
    "midi_high = 101\n",
    "midi_low = 24\n",
    "time_init=0\n",
    "\n",
    "with torch.no_grad():\n",
    "    note_state_batch = inputkernel(note_state_batch,midi_low,midi_high,time_init)\n",
    "\n",
    "note_state_batch.shape\n",
    "#input kernel's output shape = batch_size x num_notes x num_timesteps x 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data: (500, 256, 156)\n",
      "all expected: (500, 256, 156)\n"
     ]
    }
   ],
   "source": [
    "x_train = None\n",
    "y_train = None\n",
    "\n",
    "x_val = None\n",
    "y_val = None\n",
    "\n",
    "x_test = None\n",
    "y_test = None\n",
    "\n",
    "all_expected = np.empty(all_data.shape)\n",
    "all_expected[:, 0:all_expected.shape[1]-1] = all_data[:, 1:all_data.shape[1]]\n",
    "all_expected[:, all_expected.shape[1]-1] = 0\n",
    "\n",
    "all_data = np.reshape(all_data, (num_total_songs, num_time_steps, -1))\n",
    "all_expected = np.reshape(all_expected, (num_total_songs, num_time_steps, -1))\n",
    "\n",
    "print(\"all data:\", all_data.shape)\n",
    "print(\"all expected:\", all_expected.shape)\n",
    "\n",
    "note_state_batch.requires_grad_()\n",
    "\n",
    "orig_dataset = torch.utils.data.TensorDataset(note_state_batch.type(dtype), torch.from_numpy(all_expected).type(dtype))\n",
    "x_train, x_test = torch.utils.data.random_split(orig_dataset, [450, 50])\n",
    "\n",
    "x_train_loader = torch.utils.data.DataLoader(x_train, batch_size=batch_size, shuffle=True)\n",
    "x_test_loader = torch.utils.data.DataLoader(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, y, model, loss_criterion, optimizer):\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    # loss = loss_criterion(torch.max(y_pred, dim=1).indices, y)\n",
    "    loss = loss_criterion(y_pred, y)\n",
    "    ret_val = loss.item()\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return ret_val\n",
    "\n",
    "def test_step(x, y, model, loss_criterion):\n",
    "    predictions = model(x)\n",
    "    loss = loss_criterion(y_pred, y)\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save/Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name):\n",
    "    torch.save(model.state_dict(), os.path.join(saved_models_path, \"/\", model_name))\n",
    "\n",
    "def load_model_parameters(model, model_name):\n",
    "    model.load_state_dict(torch.load(os.path.join(saved_models_path, \"/\", model_name)))\n",
    "\n",
    "def load_new_model(model_name, model_constructor, *args):\n",
    "    model = model_constructor(args)\n",
    "    load_model_parameters(model, model_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.main_model import MusicGeneration\n",
    "\n",
    "model = MusicGeneration(time_sequence_len=num_time_steps, batch_size=batch_size, time_hidden_size=36, data_type=dtype)\n",
    "\n",
    "loss_criterion = torch.nn.MSELoss(reduction='sum') # = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move To Correct Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MusicGeneration(\n",
       "  (lstm_time0): LSTM(80, 36, batch_first=True)\n",
       "  (lstm_note0): LSTM(36, 2, batch_first=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    for i, data in enumerate(x_train_loader, 0):\n",
    "        x, y = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        loss = train_step(x, y, model, loss_criterion, optimizer)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\" -\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        x, y = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        loss = test_step(x, y, model, loss_criterion)\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IPDB Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[1;32m<ipython-input-30-477fd4eb848b>\u001b[0m(1)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m----> 1 \u001b[1;33m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      2 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      3 \u001b[1;33m\u001b[1;32mdef\u001b[0m \u001b[0mtest_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      4 \u001b[1;33m    \u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      5 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[1;32m<ipython-input-30-477fd4eb848b>\u001b[0m(6)\u001b[0;36mtest_code\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      4 \u001b[1;33m    \u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      5 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 6 \u001b[1;33m    \u001b[0mtrain_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      7 \u001b[1;33m    \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      8 \u001b[1;33m    \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "set_trace()\n",
    "\n",
    "def test_code():\n",
    "    set_trace()\n",
    "\n",
    "    train_iter = iter(x_train_loader)\n",
    "    data = next(train_iter)\n",
    "    x, y = data[0].to(device), data[1].to(device)    \n",
    "\n",
    "    loss = train_step(x, y, model, loss_criterion, optimizer)\n",
    "    \n",
    "    print(loss)\n",
    "    \n",
    "    data = next(train_iter)\n",
    "    x, y = data[0].to(device), data[1].to(device)\n",
    "\n",
    "    loss = train_step(x, y, model, loss_criterion, optimizer)\n",
    "    \n",
    "    print(loss)\n",
    "test_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs7643music] *",
   "language": "python",
   "name": "conda-env-cs7643music-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
